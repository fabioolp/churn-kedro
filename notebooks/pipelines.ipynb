{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bibliotecas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pickle\n",
    "\n",
    "# Buscar dados do arquivo CSV\n",
    "csv_file = \"data/01_raw/Abandono_clientes (11).csv\"\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "# Remove colunas não utilizadas\n",
    "df1 = df.drop(columns = ['RowNumber', 'CustomerId', 'Surname'])\n",
    "\n",
    "# Separando as variaveis independentes e dependentes\n",
    "y = df1['Exited']\n",
    "X = df1.copy()\n",
    "X = df1.drop(columns='Exited')\n",
    "\n",
    "# Processamento das variáveis continuas e categóricas\n",
    "x_cont = ['CreditScore', 'Balance', 'Age', 'NumOfProducts', 'EstimatedSalary', 'Tenure']\n",
    "x_cat = list(set(X)-set(x_cont))\n",
    "x_dummies = X[x_cat]\n",
    "le = LabelEncoder()\n",
    "X['Gender'] = le.fit_transform(X['Gender']) \n",
    "x_final = pd.get_dummies(data=X, columns=['Geography'])\n",
    "\n",
    "# Feature Engineering\n",
    "x_final['Salary_per_Age'] = x_final['EstimatedSalary'] / x_final['Age']\n",
    "x_final['CreditScore_per_Products'] = x_final['CreditScore'] / x_final['NumOfProducts']\n",
    "x_final['CreditScore_per_Salary'] = x_final['CreditScore'] / x_final['EstimatedSalary']\n",
    "new_cont = ['Salary_per_Age', 'CreditScore_per_Products', 'CreditScore_per_Salary']\n",
    "for var_cont in new_cont:\n",
    "    x_cont.append(var_cont)\n",
    "\n",
    "# Normalização dos dados\n",
    "# Como foi adotado RandomForest não seria necessário normalizar - mantive para testar\n",
    "scaler = MinMaxScaler()\n",
    "x_final[x_cont] = scaler.fit_transform(x_final[x_cont])\n",
    "\n",
    "# Armazena dados e scaler\n",
    "df_to_save = x_final.copy()\n",
    "df_to_save['Exited'] = y\n",
    "df_to_save.to_csv('data/03_primary/data_input_model.csv', index=False)\n",
    "with open('data/06_models/scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bibliotecas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pickle\n",
    "\n",
    "def load_data():\n",
    "    # Buscar dados do arquivo CSV\n",
    "    csv_file = \"data/01_raw/Abandono_clientes (11).csv\"\n",
    "    df = pd.read_csv(csv_file)\n",
    "\n",
    "    # Remove colunas não utilizadas\n",
    "    df1 = df.drop(columns = ['RowNumber', 'CustomerId', 'Surname'])\n",
    "\n",
    "    # Separando as variaveis independentes e dependentes\n",
    "    y = df1['Exited']\n",
    "    X = df1.copy()\n",
    "    X = df1.drop(columns='Exited')\n",
    "\n",
    "    return X, y\n",
    "\n",
    "def process_data():\n",
    "    # Processamento das variáveis continuas e categóricas\n",
    "    x_cont = ['CreditScore', 'Balance', 'Age', 'NumOfProducts', 'EstimatedSalary', 'Tenure']\n",
    "    x_cat = list(set(X)-set(x_cont))\n",
    "    x_dummies = X[x_cat]\n",
    "    le = LabelEncoder()\n",
    "    X['Gender'] = le.fit_transform(X['Gender']) \n",
    "    x_final = pd.get_dummies(data=X, columns=['Geography'])\n",
    "\n",
    "    return x_cont, x_final\n",
    "\n",
    "def feature_engineering():\n",
    "    # Feature Engineering\n",
    "    x_final = x_final.copy()\n",
    "    x_final['Salary_per_Age'] = x_final['EstimatedSalary'] / x_final['Age']\n",
    "    x_final['CreditScore_per_Products'] = x_final['CreditScore'] / x_final['NumOfProducts']\n",
    "    x_final['CreditScore_per_Salary'] = x_final['CreditScore'] / x_final['EstimatedSalary']\n",
    "    new_cont = ['Salary_per_Age', 'CreditScore_per_Products', 'CreditScore_per_Salary']\n",
    "    for var_cont in new_cont:\n",
    "        x_cont.append(var_cont)\n",
    "\n",
    "    return x_final\n",
    "\n",
    "def normalize():\n",
    "    # Normalização dos dados\n",
    "    # Como foi adotado RandomForest não seria necessário normalizar - mantive para testar\n",
    "    scaler = MinMaxScaler()\n",
    "    x_final[x_cont] = scaler.fit_transform(x_final[x_cont])\n",
    "\n",
    "    return x_final\n",
    "\n",
    "def save():\n",
    "    # Armazena dados e scaler\n",
    "    df_to_save = x_final.copy()\n",
    "    df_to_save['Exited'] = y\n",
    "    df_to_save.to_csv('data/03_primary/data_input_model.csv', index=False)\n",
    "    with open('data/06_models/scaler.pkl', 'wb') as f:\n",
    "        pickle.dump(scaler, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>predictedValues</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10002</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10003</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10004</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10005</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>10996</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>10997</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>10998</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>10999</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>11000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     RowNumber  predictedValues\n",
       "0        10001                0\n",
       "1        10002                0\n",
       "2        10003                0\n",
       "3        10004                0\n",
       "4        10005                0\n",
       "..         ...              ...\n",
       "995      10996                0\n",
       "996      10997                1\n",
       "997      10998                0\n",
       "998      10999                0\n",
       "999      11000                0\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bibliotecas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pickle\n",
    "\n",
    "# Buscar dados do arquivo CSV\n",
    "csv_file = \"data/01_raw/Abandono_teste (11).csv\"\n",
    "df = pd.read_csv(csv_file, sep=\";\")\n",
    "\n",
    "# Carrega scaler no arquivo pickle\n",
    "with open('data/06_models/scaler.pkl', 'rb') as file:\n",
    "    scaler = pickle.load(file)\n",
    "\n",
    "# Carrega modelo no arquivo pickle\n",
    "with open('data/06_models/rf_model.pkl', 'rb') as file:\n",
    "    rf_model = pickle.load(file)\n",
    "\n",
    "# Remove colunas que não serão utilizadas\n",
    "df1 = df.drop(columns=['RowNumber', 'CustomerId', 'Surname'])\n",
    "\n",
    "# Separação das variáveis\n",
    "x_cont = ['CreditScore', 'Balance', 'Age', 'NumOfProducts', 'EstimatedSalary', 'Tenure']\n",
    "x_cat = list(set(df1)-set(x_cont))\n",
    "\n",
    "# Processamento das variáveis\n",
    "x_dummies = df1[x_cat]\n",
    "le = LabelEncoder()\n",
    "df1['Gender'] = le.fit_transform(df1['Gender']) \n",
    "df_final = pd.get_dummies(data=df1, columns=['Geography'])\n",
    "\n",
    "# Feature Engineering\n",
    "df_final['Salary_per_Age'] = df_final['EstimatedSalary'] / df_final['Age']\n",
    "df_final['CreditScore_per_Products'] = df_final['CreditScore'] / df_final['NumOfProducts']\n",
    "df_final['CreditScore_per_Salary'] = df_final['CreditScore'] / df_final['EstimatedSalary']\n",
    "\n",
    "# Acrescenta novas variáveis na lista\n",
    "new_cont = ['Salary_per_Age', 'CreditScore_per_Products', 'CreditScore_per_Salary']\n",
    "for var_cont in new_cont:\n",
    "    x_cont.append(var_cont)\n",
    "\n",
    "# Normalização dos dados\n",
    "df_final[x_cont] = scaler.fit_transform(df_final[x_cont])\n",
    "\n",
    "# Realiza predição\n",
    "df['predictedValues'] = rf_model.predict(df_final)\n",
    "\n",
    "# Saida no formato solicitado no Case\n",
    "df_out = df[['RowNumber', 'predictedValues']]\n",
    "\n",
    "# Armazena resultado em CSV\n",
    "df_out.to_csv('data/08_reporting/predicted_data.csv', index=False)\n",
    "\n",
    "\n",
    "df_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bibliotecas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pickle\n",
    "\n",
    "def load_data():\n",
    "    # Buscar dados do arquivo CSV\n",
    "    csv_file = \"data/01_raw/Abandono_teste (11).csv\"\n",
    "    df = pd.read_csv(csv_file, sep=\";\")\n",
    "\n",
    "    # Carrega scaler no arquivo pickle\n",
    "    with open('data/06_models/scaler.pkl', 'rb') as file:\n",
    "        scaler = pickle.load(file)\n",
    "\n",
    "    # Carrega modelo no arquivo pickle\n",
    "    with open('data/06_models/rf_model.pkl', 'rb') as file:\n",
    "        rf_model = pickle.load(file)\n",
    "\n",
    "    # Remove colunas que não serão utilizadas\n",
    "    df1 = df.drop(columns=['RowNumber', 'CustomerId', 'Surname'])\n",
    "\n",
    "def processing_data():\n",
    "    # Separação das variáveis\n",
    "    x_cont = ['CreditScore', 'Balance', 'Age', 'NumOfProducts', 'EstimatedSalary', 'Tenure']\n",
    "    x_cat = list(set(df1)-set(x_cont))\n",
    "\n",
    "    # Processamento das variáveis\n",
    "    x_dummies = df1[x_cat]\n",
    "    le = LabelEncoder()\n",
    "    df1['Gender'] = le.fit_transform(df1['Gender']) \n",
    "    df_final = pd.get_dummies(data=df1, columns=['Geography'])\n",
    "\n",
    "    # Feature Engineering\n",
    "    df_final['Salary_per_Age'] = df_final['EstimatedSalary'] / df_final['Age']\n",
    "    df_final['CreditScore_per_Products'] = df_final['CreditScore'] / df_final['NumOfProducts']\n",
    "    df_final['CreditScore_per_Salary'] = df_final['CreditScore'] / df_final['EstimatedSalary']\n",
    "\n",
    "    # Acrescenta novas variáveis na lista\n",
    "    new_cont = ['Salary_per_Age', 'CreditScore_per_Products', 'CreditScore_per_Salary']\n",
    "    for var_cont in new_cont:\n",
    "        x_cont.append(var_cont)\n",
    "\n",
    "    # Normalização dos dados\n",
    "    df_final[x_cont] = scaler.fit_transform(df_final[x_cont])\n",
    "\n",
    "def prediction():\n",
    "    # Realiza predição\n",
    "    df['predictedValues'] = rf_model.predict(df_final)\n",
    "\n",
    "    # Saida no formato solicitado no Case\n",
    "    df_out = df[['RowNumber', 'predictedValues']]\n",
    "\n",
    "    # Armazena resultado em CSV\n",
    "    df_out.to_csv('data/08_reporting/predicted_data.csv', index=False)\n",
    "\n",
    "\n",
    "df_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
